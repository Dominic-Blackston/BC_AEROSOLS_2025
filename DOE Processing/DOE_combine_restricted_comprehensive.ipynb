{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "830f6249",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import icartt\n",
    "import os\n",
    "import warnings\n",
    "import re\n",
    "from datetime import datetime\n",
    "import csv\n",
    "from datetime import datetime, timedelta\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import glob\n",
    "from math import pi\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e029951f",
   "metadata": {},
   "outputs": [],
   "source": [
    "DOE_CAMPAIGNS = [\"ACE-ENA\", \"ACMEV\", \"BBOP\", \"CACTI\", \"CARES\", \"GOAMAZON\",\n",
    "                 \"ISDAC\", \"TCAP2012\", \"TCAP2013\"]\n",
    "\n",
    "RESTRICTED_PATH = rf\"C:\\Users\\haika\\Desktop\\May_Research\\may_datasets\\restricted_campaigns\"\n",
    "COMPREHENSIVE_PATH = rf\"C:\\Users\\haika\\Desktop\\May_Research\\may_datasets\\comprehensive_campaigns\"\n",
    "\n",
    "RESTRICTED_COMBINED_PATH = rf\"C:\\Users\\haika\\Desktop\\May_Research\\may_datasets\\restricted_combined\"\n",
    "COMPREHENSIVE_COMBINED_PATH = rf\"C:\\Users\\haika\\Desktop\\May_Research\\may_datasets\\comprehensive_combined\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "26beda5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Combining Restricted Campaigns ===\n",
      "Found 9 files to combine:\n",
      "  - CARES_restricted.csv\n",
      "  - TCAP2012_restricted.csv\n",
      "  - ACMEV_restricted.csv\n",
      "  - ACE-ENA_restricted.csv\n",
      "  - ISDAC_restricted.csv\n",
      "  - TCAP2013_restricted.csv\n",
      "  - BBOP_restricted.csv\n",
      "  - GOAMAZON_restricted.csv\n",
      "  - CACTI_restricted.csv\n",
      "Added 222 rows from CARES_restricted.csv\n",
      "Added 0 rows from TCAP2012_restricted.csv\n",
      "Added 6968 rows from ACMEV_restricted.csv\n",
      "Added 0 rows from ACE-ENA_restricted.csv\n",
      "Added 0 rows from ISDAC_restricted.csv\n",
      "Added 8644 rows from TCAP2013_restricted.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haika\\AppData\\Local\\Temp\\ipykernel_1504\\377424580.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\haika\\AppData\\Local\\Temp\\ipykernel_1504\\377424580.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
      "C:\\Users\\haika\\AppData\\Local\\Temp\\ipykernel_1504\\377424580.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added 7686 rows from BBOP_restricted.csv\n",
      "Added 0 rows from GOAMAZON_restricted.csv\n",
      "Added 1242 rows from CACTI_restricted.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\haika\\AppData\\Local\\Temp\\ipykernel_1504\\377424580.py:35: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined_df = pd.concat([combined_df, df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Combined data saved to: C:\\Users\\haika\\Desktop\\May_Research\\may_datasets\\restricted_combined\\DOE_restricted.csv\n",
      "Total rows: 24762\n",
      "Total columns: 32\n",
      "\n",
      "==================================================\n",
      "\n",
      "=== Combining Comprehensive Campaigns ===\n",
      "Found 9 files to combine:\n",
      "  - TCAP2013_comprehensive.csv\n",
      "  - GOAMAZON_comprehensive.csv\n",
      "  - ACMEV_comprehensive.csv\n",
      "  - ISDAC_comprehensive.csv\n",
      "  - BBOP_comprehensive.csv\n",
      "  - CARES_comprehensive.csv\n",
      "  - ACE-ENA_comprehensive.csv\n",
      "  - TCAP2012_comprehensive.csv\n",
      "  - CACTI_comprehensive.csv\n",
      "Added 18901 rows from TCAP2013_comprehensive.csv\n",
      "Added 331893 rows from GOAMAZON_comprehensive.csv\n",
      "Added 55849 rows from ACMEV_comprehensive.csv\n",
      "Added 441569 rows from ISDAC_comprehensive.csv\n",
      "Added 64847 rows from BBOP_comprehensive.csv\n",
      "Added 2838 rows from CARES_comprehensive.csv\n",
      "Added 546787 rows from ACE-ENA_comprehensive.csv\n",
      "Added 15523 rows from TCAP2012_comprehensive.csv\n",
      "Added 38596 rows from CACTI_comprehensive.csv\n",
      "\n",
      "Combined data saved to: C:\\Users\\haika\\Desktop\\May_Research\\may_datasets\\comprehensive_combined\\DOE_comprehensive.csv\n",
      "Total rows: 1516803\n",
      "Total columns: 50\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def combine_doe_campaigns(source_path, output_path, output_filename):\n",
    "    \"\"\"\n",
    "    Combine all CSV files containing DOE campaign names from source_path\n",
    "    and save to output_path with given filename\n",
    "    \"\"\"\n",
    "    # Create output directory if it doesn't exist\n",
    "    os.makedirs(output_path, exist_ok=True)\n",
    "    \n",
    "    # Find all CSV files that contain any DOE campaign name\n",
    "    matching_files = []\n",
    "    \n",
    "    for campaign in DOE_CAMPAIGNS:\n",
    "        # Look for CSV files containing the campaign name\n",
    "        pattern = os.path.join(source_path, f\"*{campaign}*.csv\")\n",
    "        campaign_files = glob.glob(pattern)\n",
    "        matching_files.extend(campaign_files)\n",
    "    \n",
    "    # Remove duplicates (in case a file matches multiple campaign names)\n",
    "    matching_files = list(set(matching_files))\n",
    "    \n",
    "    if not matching_files:\n",
    "        print(f\"No CSV files found containing DOE campaign names in {source_path}\")\n",
    "        return\n",
    "    \n",
    "    print(f\"Found {len(matching_files)} files to combine:\")\n",
    "    for file in matching_files:\n",
    "        print(f\"  - {os.path.basename(file)}\")\n",
    "    \n",
    "    # Read and combine all CSV files\n",
    "    combined_df = pd.DataFrame()\n",
    "    \n",
    "    for file_path in matching_files:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            combined_df = pd.concat([combined_df, df], ignore_index=True)\n",
    "            print(f\"Added {len(df)} rows from {os.path.basename(file_path)}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error reading {os.path.basename(file_path)}: {e}\")\n",
    "    \n",
    "    # Save combined data\n",
    "    output_file_path = os.path.join(output_path, output_filename)\n",
    "    combined_df.to_csv(output_file_path, index=False)\n",
    "    \n",
    "    print(f\"\\nCombined data saved to: {output_file_path}\")\n",
    "    print(f\"Total rows: {len(combined_df)}\")\n",
    "    print(f\"Total columns: {len(combined_df.columns)}\")\n",
    "    \n",
    "    return combined_df\n",
    "\n",
    "# 1. Combine restricted campaigns\n",
    "print(\"=== Combining Restricted Campaigns ===\")\n",
    "restricted_combined = combine_doe_campaigns(\n",
    "    RESTRICTED_PATH, \n",
    "    RESTRICTED_COMBINED_PATH, \n",
    "    \"DOE_restricted.csv\"\n",
    ")\n",
    "\n",
    "print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "\n",
    "# 2. Combine comprehensive campaigns  \n",
    "print(\"=== Combining Comprehensive Campaigns ===\")\n",
    "comprehensive_combined = combine_doe_campaigns(\n",
    "    COMPREHENSIVE_PATH, \n",
    "    COMPREHENSIVE_COMBINED_PATH, \n",
    "    \"DOE_comprehensive.csv\"\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
